# 1102 컴퓨팅

- 머신러닝: 데이터를 통해 배우는 알고리즘

  \-> 지금까지 배우지 않은 데이터 예측할 수 있는

  \- >데이터의 양 중요 -> 빅데이터, 슈퍼컴퓨터

- 그래서 리눅스 배워야함: 슈퍼컴퓨터 접근하기 위해서
- C: 컴퓨팅 빨리위해, python : abstraction많이 걸려 오래 걸릴 수 있음
- 하드웨어: GPU, YPU 





- logistic regression 
  - going forward
  - Gradient DescetnL: cost function 작아지는 방향으로 log로 미분함
    - 미분값 0되는방향으로 weight 가 costffunction 작아지는 방향으로 왔다갔다 
    - alpha :learning late
    - rate를 costfunction(weight)으로 미분 위해 , chain rule으로 미분함
    - Going backwards: lost function을 미분부터 시작해서 하나씩 거꾸로옴   
    - forward: input->output 방향

- deep learning - going deeper! : 여러 layer값을 거침 layer 10개

  - layer의 index 필요해짐

  - 똑같은 연산을 layer별로 연산 ->z 결과 나옴

  - z를 비선형 함수 통과시킴, g: activate function. 

    l번쨰 레이어라 시그노이드 함수 아니여도 되는  nonlayer함수 들어감 :값이 아니라 아직 레이어라서

- L개 만큼 쌓음 

- a[0]->a[1]->,,,,,a[L-1]=>하나합침 a[L] 여기서 g는 시그노이드 함수가 됨 

- 최종 추정값 yhat을 가져감

- 거꾸로 가기

- w1,w2로 미분 할 수 있어야 각레이어에 있는 w로 costfunction 미분 할 수 있어야 함

- 최종 결과물을 미분하고, chain rule로 계쏙 뒤로 가면 모든레이어에 있는 weight로 cost function 을 미분 한 결과를 구할수 있어짐, 합산하면됨

- cost functin을 a[L]로 미분한 값 : da[L]

- 이렇게 최적화 해나감



- g : lone-linear 함수 (커브,각,,,직선 아닌 함수)

- signoid/ tanh(평균이 0이돼어 더 용이) : 느리다

- ReLU: z가 0보다 작으면 다 0 , 훨씬 빠르고 단순, 요즘에 많이 사용

- 약간의 값을 살린(음수) : tRELU도 나옴 

- 왜 비선형 씀?

- 딥러닝: 레이어 여러개 쌓음

- 레이어를 지나면서 더 복잡한 연산, 복잡한해석 위한 과정

- non-linear T를 통과 시켜야 더 복잡한 해석이 가능함

- 다 선형이면 여러개 레이어 으미 없음 ->결국 레이어 하나로 문 들 수 있음

- 레이어 짬뽕위해 추가시켜 나가야 복잡한 딥러닝 가능

- W의 초기값 엌케 구함

- cash : 저장하고 있다. 빨리 쓸 수 있는 하드웨어 위치에 저장해놓음

- 너무 큰 값으로 weight주면 느리고 안좋음

- 정규분포 값으로 랜덤 하게 뽑고 작게 만들어줌 *0.01(평균이 주로 작은값이 나오도록)

- 파라미터들에 영향을 미치는 hyperparpameter들이 있음

- D와 W 최적화 과정인데, 얘네에 영향을 미치는 hyperparameters

  - Learningrate : 알파 ; 정확도, 속도에 영향 미침

  - #of iterations : forward,bakward 몇번 할거냐

  - #of hidden layers

  - activation functions

    ​	이게 다 empirical 하게 해야함, 그래서 빅데이터 빠르게 처리하는 컴퓨팅 필요

  

- 딥러닝 네트워크: 로지스틱 리그래션 여러개의 레이어로 처리한거 
- forward,backward
- layer사이 다 weight연결되거 -> 신경망 MLP
- 레이어, 히든레이어, 아웃풋레이어 있음
- 복잡도 더해주기 위해 비선형 함수
- 랜덤리 웨이트 정함



- 어떻게 좋은 DNN모델 얻냐
- 뭐가 좋은 모델인지?
  - 트레이닝할떄 안쓴 데이터를 잘 구분하냐가 모델 좋은지 판단 
  - underfitting(너무 심플)-appropriatefitting(오히려 판단에 좋음)-overfitting(예외가 가차없이 발생할 위험 큼)
  - dataset
    - Training set, validation set, test set
    - Training-validation 두개 비교하면서 계쏙 좋은 모델 최적화 함
    - 성능평가는 test dataset 으로 
    - 알고리즘 





- project
- 히든 레이어 하나만
-  