# 1105 하둡 MC 

- 하둡

  큰사이즈 저장

  구글 웹사이트 정보 저장 위해 

  95년 웹사이트 시장열림 - 하둡이 저장 잘 보관 유저가 필요한 정보 제공 

  컴퓨터 여러개 붙여서 분산 활동을 만들자. 

  datacenter라 함 

  HDFS 분산 저장 시스템(storage)

  MapReduce 분산 처리 시스템 (computation)

네트워크 연결, 다른 연결 체제 설치 - 여러 컴퓨터 연결(머신 제한 없음, 라즈베리 파이으로도 가능)

처리하고 싶은 데이터 양만큼 얼마든지 할 수 있게 됨

하둡한테 큰파일 저장해줘하면: 일정단위로 쪼개서 여러시스템에 분산해서 저장해줌 : HDFS가 하는일

replication까지(복제)해서 저장함, 머신 고장나도 괜찮게

Map Reduce : 분산 저장, 분산 처리 시스템 도 각자 머신에서 함 -> but 자바로 짜는 프로그래밍이 어려움 -> pig, Hive, Mahout, Oozie 등이 다른 언어로도 할 수 있게 해줌

-> 오래 걸림 ---> 이거 보완 위해 빠른 spark가 나옴

분산처리 시스템 : mapreduce가 가진 분산처리시스템 단점을 보완(100배 빠르무)

클러스터 : 여러개 컴터 연결되 하나의 싀스템처럼 동작하는 컴퓨터들 집합_네임노드 하나와 여러개 데이터 노드로 구성됨 



하둡에코 시스템



mapreduce

머신들 노드라고 부름

데이터 처리 : 변환(각자 머신에서), 집계 (reduce가 하나로 데려옴)

5개 머심 맵작업, 결과를 reduce하는 머신한테 보냄

이때 shuffle이 (적당히뒤섞임_sort)이 일어남



hadoop: 일하면서 중간중간에 한거 저장 다시 읽고 다시 저장...하드디스크에다가 일중간중간에 다시 보관 다시 읽고...

하둡의 맵리듀스 더 빠르게 할려고 spark가 나옴

hadopfilesystem은 그대로

mapreduce를 바꿈

램에 저장

빅데이터 보관: 하둡파일시스템

빅데이터 처리: 초반 하둡 이제는 스파크(자바로 개발됨_람다 구문 이용해 간단히 구현됨)

spark: 업그레이드 활발함

MLlib:spark 머신러닝 _ 최신버전 알고리즘은 사이킷런이 나음



- spark

python 은 기본 언어아니라 따로 설치 필요

spark에서 자가복구 기능 내장한 분산 데이터 셋 (분산처리하는 기본 api) : RDD

이안에 많은 객체 떄려넣음

원하는것으로 RDD객체 만들어주면 내부적으로 처리함

RDD는 read only

2가지 기능 으로 RDD 객체 처리

tansformation(map같은_변환작업), action*(educe같은 _최종내보냄)이라는 연산으로 나뉨

여러번의 trans와 한번/몇번의 action

lineage에 해야할일 다 적어놈

그 다음에 움직임 -> Lazy execution을 지원함

lineage 통해 execution plan을 짬



Transformation에 함수 아무리 호출해도 action안함, lineage에 계쏙 ㅁ저장

Actions의 함수가 action을 시행 

RDD객체 받아서 리턴 값도 RDD



